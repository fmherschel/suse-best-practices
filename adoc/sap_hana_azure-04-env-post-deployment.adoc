=== Deployment Validation

The `terraform apply` command output provides information about the created cluster.

.`terraform apply` output sample:
======== 
[subs="specialchars,quotes,attributes"]
----
$ terraform apply
*[OUTPUT TRIMMED]*

*module.hana_node.null_resource.hana_node_provisioner[1]: Creation complete after 36m4s [id=2647934812513863765]*

Apply complete! Resources: 33 added, 0 changed, 0 destroyed.

Outputs:

cluster_nodes_ip = [
  *"{node1PrIP}",*
  *"{node2PrIP}",*
]
cluster_nodes_name = [
  *"vmhana01",*
  *"vmhana02",*
]
cluster_nodes_public_ip = [
  *"{node1PuIP}",*
  *"{node2PuIP}",*
]
cluster_nodes_public_name = [
  "",
  "",
]
drbd_ip = []
drbd_name = []
drbd_public_ip = []
drbd_public_name = []
iscsisrv_ip = [
  *"{iscsiPrIP}",*
]
iscsisrv_name = [
  *"vmiscsisrv",*
]
iscsisrv_public_ip = [
  *"{iscsiPuIP}",*
]
iscsisrv_public_name = [
  "",
]
*[OUTPUT TRIMMED]*
----
========


=== Cluster Status Validation

Connect to any cluster node to check the cluster status:

.Cluster status check:
========
. Copy the created SSH keys to your default SSH directory:
+
[subs="specialchars,quotes,attributes"]
----
$ cp -v /home/*<{projUser}>*/ha-sap-terraform-deployments/salt/hana_node/files/sshkeys/cluster.id_rsa*  /home/*<{projUser}>*/.ssh/
----

. Change the SSH keys files permissions as follows:
+
[subs="specialchars,quotes,attributes"]
----
$ chmod -v 400 /home/*<{projUser}>*/.ssh/cluster.id_rsa

$ chmod -v 600 /home/*<{projUser}>*/.ssh/cluster.id_rsa.pub 
----

. Connect to any cluster node:
+
[subs="specialchars,quotes,attributes"]
----
$ ssh -i .ssh/cluster.id_rsa *<ADMIN USER>*@*<CLUSTER NODE PUBLIC IP>*
----

. Check the cluster status:
+
[subs="specialchars,quotes,attributes"]
----
$ hostname
*vmhana01*

$ sudo su -
----
+
[subs="specialchars,quotes,attributes"]
----
vmhana01:~ # crm_mon -rnf1
Stack: corosync
Current DC: vmhana01 (version 1.1.18+20180430.b12c320f5-3.18.1-b12c320f5) - partition with quorum
Last updated: Thu Mar  5 16:04:23 2020
Last change: Thu Mar  5 16:04:09 2020 by root via crm_attribute on vmhana01

2 nodes configured
7 resources configured

Node vmhana01: online
        *rsc_SAPHana_PRD_HDB00  (ocf::suse:SAPHana):    Master*
        *rsc_ip_PRD_HDB00       (ocf::heartbeat:IPaddr2):       Started*
        stonith-sbd     (stonith:external/sbd): Started
        *rsc_SAPHanaTopology_PRD_HDB00  (ocf::suse:SAPHanaTopology):    Started*
        *rsc_socat_PRD_HDB00    (ocf::heartbeat:anything):      Started*
Node vmhana02: online
        *rsc_SAPHana_PRD_HDB00  (ocf::suse:SAPHana):    Slave*
        *rsc_SAPHanaTopology_PRD_HDB00  (ocf::suse:SAPHanaTopology):    Started*

No inactive resources


Migration Summary:
* Node vmhana01:
* Node vmhana02:
----
========

